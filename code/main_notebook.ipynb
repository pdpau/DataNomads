{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An치lisis y predicci칩n de flujos de movilidad vacacional en Espa침a Peninsula-Islas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "#%pip install -q -U matplotlib numpy pandas scikit-learn seaborn\n",
    "#%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2022 = \"../data/movilidad_provincias_2022.csv\"\n",
    "path_2023 = \"../data/movilidad_provincias_2023.csv\"\n",
    "path_2024 = \"../data/movilidad_provincias_2024.csv\"\n",
    "\n",
    "original_data_2022 = pd.read_csv(path_2022, sep=\",\")\n",
    "original_data_2023 = pd.read_csv(path_2023, sep=\",\")\n",
    "original_data_2024 = pd.read_csv(path_2024, sep=\",\")\n",
    "\n",
    "df_2022 = original_data_2022.copy()\n",
    "df_2023 = original_data_2023.copy()\n",
    "df_2024 = original_data_2024.copy()\n",
    "\n",
    "df = pd.concat([df_2022, df_2023, df_2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df_2022.info()\n",
    "df_2022.head() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDA (passar aqui del notebook del eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Wrangling\n",
    "All this process is known as **Data Wrangling**. In particular, the whole data wrangling process implies:\n",
    "- Define and apply an strategy for nulls and coding for categorical variables\n",
    "- Analyze the variables distribution and correlation between them\n",
    "- Remove outliers\n",
    "- etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FILTERING\n",
    "# Keep only the rows with destination province = ['Balears, Illes', 'Palmas, Las', 'Santa Cruz de Tenerife']\n",
    "insular_provinces = ['Balears, Illes', 'Palmas, Las', 'Santa Cruz de Tenerife']\n",
    "df = df[df['provincia_destino_name'].isin(insular_provinces)]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df.copy()\n",
    "\n",
    "# Add two new columns, day_of_week and month\n",
    "features_df['date'] = pd.to_datetime(features_df['day'])\n",
    "features_df['day_of_week'] = features_df['date'].dt.day_name()\n",
    "features_df['month'] = features_df['date'].dt.month\n",
    "features_df['year'] = features_df['date'].dt.year\n",
    "features_df.drop(columns=['day'], inplace=True)\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all the trips to the same destination province\n",
    "total_llegadas_islas = features_df.groupby(['date', 'provincia_destino_name', 'day_of_week', 'month', 'year'])['viajes'].sum().reset_index()\n",
    "total_llegadas_islas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv for the web app\n",
    "total_llegadas_islas.to_csv('web/model_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df1 = total_llegadas_islas.copy()\n",
    "df1.drop(columns=['date'], inplace=True)\n",
    "df1.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le_day_of_week = LabelEncoder()\n",
    "df1['day_of_week'] = le_day_of_week.fit_transform(df1['day_of_week'])\n",
    "le_provincia_destino_name = LabelEncoder()\n",
    "df1['provincia_destino_name'] = le_provincia_destino_name.fit_transform(df1['provincia_destino_name'])\n",
    "\n",
    "# Correlation matrix\n",
    "\"\"\" plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df1.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1.drop(columns=['viajes'])\n",
    "target = df1['viajes']\n",
    "\n",
    "X = features\n",
    "y = target\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with best model\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST REGRESSOR\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred_rfr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT BOOSTING REGRESSOR\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicci칩n de datos fake\n",
    "fake_data = pd.DataFrame({'provincia_destino_name': ['Balears, Illes'], 'day_of_week': ['Friday'], 'month': [1]})\n",
    "\n",
    "fake_data['day_of_week'] = le_day_of_week.transform(fake_data['day_of_week'])\n",
    "fake_data['provincia_destino_name'] = le_provincia_destino_name.transform(fake_data['provincia_destino_name'])\n",
    "\n",
    "fake_data\n",
    "\n",
    "y_pred_xgb_fake = xgb.predict(fake_data)\n",
    "y_pred_rfr_fake = rfr.predict(fake_data)\n",
    "y_pred_gbr_fake = gbr.predict(fake_data)\n",
    "\n",
    "print(f\"XGBoost: {y_pred_xgb_fake}\")\n",
    "print(f\"Random Forest Regressor: {y_pred_rfr_fake}\")\n",
    "print(f\"Gradient Boosting Regressor: {y_pred_gbr_fake}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Evaluation metrics\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rfr)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rfr)\n",
    "r2_rf = r2_score(y_test, y_pred_rfr)\n",
    "\n",
    "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
    "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(f\"Random Forest Regressor: MSE = {mse_rf}, MAE = {mae_rf}, R2 = {r2_rf}\")\n",
    "print(f\"Gradient Boosting Regressor: MSE = {mse_gbr}, MAE = {mae_gbr}, R2 = {r2_gbr}\")\n",
    "print(f\"XGBoost: MSE = {mse_xgb}, MAE = {mae_xgb}, R2 = {r2_xgb}\")\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "\n",
    "\n",
    "#print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAINABILITY OF THE MODEL (ELI5, LIME, SHAP) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classifier: Precision, recall, f1-score, accuracy, confusion matrix, DENSITY CHARTS, ...\n",
    "# For regressor: R2, RMSE, MAE, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "\"\"\" from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "confusion_matrix_gbr = confusion_matrix(y_test, y_pred_gbr)\n",
    "confusion_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "confusion_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "sns.heatmap(confusion_matrix_lr, annot=True, cmap='coolwarm', ax=ax[0])\n",
    "sns.heatmap(confusion_matrix_gbr, annot=True, cmap='coolwarm', ax=ax[1])\n",
    "sns.heatmap(confusion_matrix_rf, annot=True, cmap='coolwarm', ax=ax[2])\n",
    "sns.heatmap(confusion_matrix_xgb, annot=True, cmap='coolwarm', ax=ax[3])\n",
    "ax[0].set_title(\"Linear Regression\")\n",
    "ax[1].set_title(\"Gradient Boosting Regressor\")\n",
    "ax[2].set_title(\"Random Forest\")\n",
    "ax[3].set_title(\"XGBoost\")\n",
    "plt.show() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
